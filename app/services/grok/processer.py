"""Grok API å“åº”å¤„ç†å™¨æ¨¡å—"""

import json
import uuid
import time
import asyncio
from typing import AsyncGenerator

from app.core.config import setting
from app.core.exception import GrokApiException
from app.core.logger import logger
from app.models.openai_schema import (
    OpenAIChatCompletionResponse,
    OpenAIChatCompletionChoice,
    OpenAIChatCompletionMessage,
    OpenAIChatCompletionChunkResponse,
    OpenAIChatCompletionChunkChoice,
    OpenAIChatCompletionChunkMessage
)
from app.services.grok.cache import image_cache_service, video_cache_service
from app.services.cloudinary import cloudinary_client


class StreamTimeoutManager:
    """æµå¼å“åº”è¶…æ—¶ç®¡ç†å™¨"""
    
    def __init__(self, chunk_timeout: int = 120, first_response_timeout: int = 30, total_timeout: int = 600):
        """åˆå§‹åŒ–è¶…æ—¶ç®¡ç†å™¨
        
        Args:
            chunk_timeout: æ•°æ®å—é—´éš”è¶…æ—¶ï¼ˆç§’ï¼‰
            first_response_timeout: é¦–æ¬¡å“åº”è¶…æ—¶ï¼ˆç§’ï¼‰
            total_timeout: æ€»è¶…æ—¶é™åˆ¶ï¼ˆç§’ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶ï¼‰
        """
        self.chunk_timeout = chunk_timeout
        self.first_response_timeout = first_response_timeout
        self.total_timeout = total_timeout
        
        self.start_time = asyncio.get_event_loop().time()
        self.last_chunk_time = self.start_time
        self.first_chunk_received = False
    
    def check_timeout(self) -> tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦è¶…æ—¶
        
        Returns:
            (is_timeout, timeout_message): æ˜¯å¦è¶…æ—¶åŠè¶…æ—¶ä¿¡æ¯
        """
        current_time = asyncio.get_event_loop().time()
        
        # æ£€æŸ¥é¦–æ¬¡å“åº”è¶…æ—¶
        if not self.first_chunk_received:
            if current_time - self.start_time > self.first_response_timeout:
                return True, f"é¦–æ¬¡å“åº”è¶…æ—¶ ({self.first_response_timeout}ç§’æœªæ”¶åˆ°é¦–ä¸ªæ•°æ®å—)"
        
        # æ£€æŸ¥æ€»è¶…æ—¶
        if self.total_timeout > 0:
            if current_time - self.start_time > self.total_timeout:
                return True, f"æµå¼å“åº”æ€»è¶…æ—¶ ({self.total_timeout}ç§’)"
        
        # æ£€æŸ¥æ•°æ®å—é—´éš”è¶…æ—¶
        if self.first_chunk_received:
            if current_time - self.last_chunk_time > self.chunk_timeout:
                return True, f"æ•°æ®å—é—´éš”è¶…æ—¶ ({self.chunk_timeout}ç§’æ— æ–°æ•°æ®)"
        
        return False, ""
    
    def mark_chunk_received(self):
        """æ ‡è®°æ”¶åˆ°æ•°æ®å—"""
        self.last_chunk_time = asyncio.get_event_loop().time()
        self.first_chunk_received = True
    
    def get_total_duration(self) -> float:
        """è·å–æ€»è€—æ—¶ï¼ˆç§’ï¼‰"""
        return asyncio.get_event_loop().time() - self.start_time


class GrokResponseProcessor:
    """Grok API å“åº”å¤„ç†å™¨"""

    @staticmethod
    async def process_normal(response, auth_token: str, model: str = None) -> OpenAIChatCompletionResponse:
        """å¤„ç†éæµå¼å“åº”"""
        response_closed = False
        try:
            for chunk in response.iter_lines():
                if not chunk:
                    continue

                data = json.loads(chunk.decode("utf-8"))

                # é”™è¯¯æ£€æŸ¥
                if error := data.get("error"):
                    raise GrokApiException(
                        f"APIé”™è¯¯: {error.get('message', 'æœªçŸ¥é”™è¯¯')}",
                        "API_ERROR",
                        {"code": error.get("code")}
                    )

                # æå–å“åº”æ•°æ®
                grok_resp = data.get("result", {}).get("response", {})
                

                
                # æå–è§†é¢‘æ•°æ®
                if video_resp := grok_resp.get("streamingVideoGenerationResponse"):
                    
                    if video_url := video_resp.get("videoUrl"):
                        logger.debug(f"[Processor] æ£€æµ‹åˆ°è§†é¢‘ç”Ÿæˆ: {video_url}")
                        full_video_url = f"https://assets.grok.com/{video_url}"
                        
                        # ä¸‹è½½å¹¶ç¼“å­˜è§†é¢‘
                        try:
                            cache_path = await video_cache_service.download_video(f"/{video_url}", auth_token)
                            if cache_path:
                                cloudinary_url = await asyncio.to_thread(cloudinary_client.upload_video, str(cache_path))
                                logger.info(f"[Processor] âœ… Video uploaded to Cloudinary: {cloudinary_url}")
                                content = f'<video src="{cloudinary_url}" controls="controls" width="500" height="300"></video>\n'
                            else:
                                logger.warning(f"[Processor] âš ï¸  Video caching failed, using direct URL")
                                content = f'<video src="{full_video_url}" controls="controls" width="500" height="300"></video>\n'
                        except Exception as e:
                            logger.error(f"[Processor] âŒ Error caching video: {type(e).__name__}: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            content = f'<video src="{full_video_url}" controls="controls" width="500" height="300"></video>\n'
                        
                        logger.info(f"[Processor] Final video content: {content}")
                        
                        # è¿”å›è§†é¢‘å“åº”
                        result = OpenAIChatCompletionResponse(
                            id=f"chatcmpl-{uuid.uuid4()}",
                            object="chat.completion",
                            created=int(time.time()),
                            model=model or "grok-imagine-0.9",
                            choices=[OpenAIChatCompletionChoice(
                                index=0,
                                message=OpenAIChatCompletionMessage(
                                    role="assistant",
                                    content=content
                                ),
                                finish_reason="stop"
                            )],
                            usage=None
                        )
                        response_closed = True
                        response.close()
                        return result
                    else:
                        # Keep iterating - we haven't reached 100% yet
                        continue

                # æå–æ¨¡å‹å“åº”
                model_response = grok_resp.get("modelResponse")
                if not model_response:
                    continue

                # æ£€æŸ¥ modelResponse ä¸­çš„é”™è¯¯
                if error_msg := model_response.get("error"):
                    raise GrokApiException(
                        f"æ¨¡å‹å“åº”é”™è¯¯: {error_msg}",
                        "MODEL_ERROR"
                    )

                # æ„å»ºå“åº”å†…å®¹
                model_name = model_response.get("model")
                content = model_response.get("message", "")

                # æå–å›¾ç‰‡æ•°æ®
                if images := model_response.get("generatedImageUrls"):
                    # è·å–å›¾ç‰‡è¿”å›æ¨¡å¼
                    image_mode = setting.global_config.get("image_mode", "url")

                    for img in images:
                        try:
                            if image_mode == "base64":
                                # base64 æ¨¡å¼ï¼šä¸‹è½½å¹¶è½¬æ¢ä¸º base64
                                base64_str = await image_cache_service.download_base64(f"/{img}", auth_token)
                                if base64_str:
                                    content += f"\n![Generated Image]({base64_str})"
                                else:
                                    content += f"\n![Generated Image](https://assets.grok.com/{img})"
                            else:
                                # url æ¨¡å¼ï¼šç¼“å­˜å¹¶è¿”å›é“¾æ¥
                                cache_path = await image_cache_service.download_image(f"/{img}", auth_token)
                                if cache_path:
                                    img_path = img.replace('/', '-')
                                    base_url = setting.global_config.get("base_url", "")
                                    img_url = f"{base_url}/images/{img_path}" if base_url else f"/images/{img_path}"
                                    content += f"\n![Generated Image]({img_url})"
                                else:
                                    content += f"\n![Generated Image](https://assets.grok.com/{img})"
                        except Exception as e:
                            logger.warning(f"[Processor] å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")
                            content += f"\n![Generated Image](https://assets.grok.com/{img})"

                # è¿”å› OpenAI å“åº”æ ¼å¼
                result = OpenAIChatCompletionResponse(
                    id=f"chatcmpl-{uuid.uuid4()}",
                    object="chat.completion",
                    created=int(time.time()),
                    model=model_name,
                    choices=[OpenAIChatCompletionChoice(
                        index=0,
                        message=OpenAIChatCompletionMessage(
                            role="assistant",
                            content=content
                        ),
                        finish_reason="stop"
                    )],
                    usage=None
                )
                response_closed = True
                response.close()
                return result

            raise GrokApiException("æ— å“åº”æ•°æ®", "NO_RESPONSE")

        except json.JSONDecodeError as e:
            logger.error(f"[Processor] JSONè§£æå¤±è´¥: {e}")
            raise GrokApiException(f"JSONè§£æå¤±è´¥: {e}", "JSON_ERROR") from e
        except Exception as e:
            logger.error(f"[Processor] å¤„ç†å“åº”æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {type(e).__name__}: {e}")
            raise GrokApiException(f"å“åº”å¤„ç†é”™è¯¯: {e}", "PROCESS_ERROR") from e
        finally:
            # ç¡®ä¿å“åº”å¯¹è±¡è¢«å…³é—­ï¼Œé¿å…åŒé‡é‡Šæ”¾
            if not response_closed and hasattr(response, 'close'):
                try:
                    response.close()
                except Exception as e:
                    logger.warning(f"[Processor] å…³é—­å“åº”å¯¹è±¡æ—¶å‡ºé”™: {e}")

    @staticmethod
    async def process_stream(response, auth_token: str) -> AsyncGenerator[str, None]:
        """å¤„ç†æµå¼å“åº”"""
        # æµå¼ç”ŸæˆçŠ¶æ€
        is_image = False
        is_thinking = False
        thinking_finished = False
        chunk_index = 0
        model = None
        filtered_tags = setting.grok_config.get("filtered_tags", "").split(",")
        video_progress_started = False
        last_video_progress = -1
        response_closed = False

        # åˆå§‹åŒ–è¶…æ—¶ç®¡ç†å™¨
        timeout_manager = StreamTimeoutManager(
            chunk_timeout=setting.grok_config.get("stream_chunk_timeout", 120),
            first_response_timeout=setting.grok_config.get("stream_first_response_timeout", 30),
            total_timeout=setting.grok_config.get("stream_total_timeout", 600)
        )

        def make_chunk(chunk_content: str, finish: str = None):
            """ç”ŸæˆOpenAIæ ¼å¼çš„å“åº”å—"""
            chunk_data = OpenAIChatCompletionChunkResponse(
                id=f"chatcmpl-{uuid.uuid4()}",
                created=int(time.time()),
                model=model or "grok-4-mini-thinking-tahoe",
                choices=[OpenAIChatCompletionChunkChoice(
                    index=chunk_index,
                    delta=OpenAIChatCompletionChunkMessage(
                        role="assistant",
                        content=chunk_content
                    ) if chunk_content else {},
                    finish_reason=finish
                )]
            ).model_dump()
            # SSE æ ¼å¼è¿”å›
            return f"data: {json.dumps(chunk_data)}\n\n"

        try:
            for chunk in response.iter_lines():
                # è¶…æ—¶æ£€æŸ¥
                is_timeout, timeout_msg = timeout_manager.check_timeout()
                if is_timeout:
                    logger.warning(f"[Processor] {timeout_msg}")
                    yield make_chunk("", "stop")
                    yield "data: [DONE]\n\n"
                    return

                logger.debug(f"[Processor] æ¥æ”¶åˆ°æ•°æ®å—: {len(chunk)} bytes")
                
                # DEBUG: Log RAW chunk data from Grok before any processing
                if chunk:
                    try:
                        raw_decoded = chunk.decode("utf-8")
                        logger.debug(f"[Processor] ğŸ”´ RAW CHUNK FROM GROK: {raw_decoded}")
                    except Exception as e:
                        logger.debug(f"[Processor] Could not decode chunk: {e}")
                
                if not chunk:
                    continue

                try:
                    data = json.loads(chunk.decode("utf-8"))

                    # é”™è¯¯æ£€æŸ¥
                    if error := data.get("error"):
                        error_msg = error.get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"[Processor] Grok APIè¿”å›é”™è¯¯: {error_msg}")
                        yield make_chunk(f"Error: {error_msg}", "stop")
                        yield "data: [DONE]\n\n"
                        return

                    # æå–å“åº”æ•°æ®
                    grok_resp = data.get("result", {}).get("response", {})
                    logger.debug(f"[Processor] è§£æå“åº”æ•°æ®: {len(grok_resp)} å­—æ®µ")
                    
                    if not grok_resp:
                        continue

                    # æ›´æ–°æ¨¡å‹åç§°
                    if user_resp := grok_resp.get("userResponse"):
                        if m := user_resp.get("model"):
                            model = m

                    # æå–è§†é¢‘æ•°æ®
                    if video_resp := grok_resp.get("streamingVideoGenerationResponse"):
                        logger.debug(f"[Processor] ğŸ¬ Stream: Video response chunk: {json.dumps(video_resp, indent=2)}")
                        progress = video_resp.get("progress", 0)
                        
                        if progress > last_video_progress:
                            last_video_progress = progress
                            logger.info(f"[Processor] ğŸ“Š Video generation progress: {progress}%")
                            
                            # æ·»åŠ  <think> æ ‡ç­¾
                            if not video_progress_started:
                                content = f"<think>è§†é¢‘å·²ç”Ÿæˆ{progress}%\n"
                                video_progress_started = True
                                logger.info(f"[Processor] Started video progress tracking")
                            elif progress < 100:
                                content = f"è§†é¢‘å·²ç”Ÿæˆ{progress}%\n"
                            else:
                                # è¿›åº¦100%æ—¶å…³é—­ <think> æ ‡ç­¾å¹¶ç«‹å³å¤„ç†è§†é¢‘
                                logger.info(f"[Processor] âœ… Video generation complete (100%)")
                                content = f"è§†é¢‘å·²ç”Ÿæˆ{progress}%</think>\n"
                                
                                # ç«‹å³ä¸‹è½½å¹¶ç¼“å­˜è§†é¢‘
                                if v_url := video_resp.get("videoUrl"):
                                    logger.info(f"[Processor] ğŸ¥ Video URL found: {v_url}")
                                    full_video_url = f"https://assets.grok.com/{v_url}"
                                    logger.info(f"[Processor] Full video URL: {full_video_url}")
                                    
                                    try:
                                        logger.info(f"[Processor] Attempting to cache video...")
                                        cache_path = await video_cache_service.download_video(f"/{v_url}", auth_token)
                                        if cache_path:
                                            logger.info(f"[Processor] âœ… Video cached at: {cache_path}")
                                            cloudinary_url = await asyncio.to_thread(cloudinary_client.upload_video, str(cache_path))
                                            logger.info(f"[Processor] âœ… Video uploaded to Cloudinary: {cloudinary_url}")
                                            content += f'<video src="{cloudinary_url}" controls="controls"></video>\n'
                                        else:
                                            logger.warning(f"[Processor] âš ï¸  Video caching failed, using direct URL")
                                            content += f'<video src="{full_video_url}" controls="controls"></video>\n'
                                    except Exception as e:
                                        logger.error(f"[Processor] âŒ Error caching video: {type(e).__name__}: {e}")
                                        import traceback
                                        logger.error(traceback.format_exc())
                                        content += f'<video src="{full_video_url}" controls="controls"></video>\n'
                                    
                                    logger.info(f"[Processor] Final video content: {content}")
                                else:
                                    logger.error(f"[Processor] âŒ Progress is 100% but no videoUrl found!")

                            yield make_chunk(content)
                            timeout_manager.mark_chunk_received()
                            chunk_index += 1
                        
                        continue

                    # æ£€æŸ¥ç”Ÿæˆæ¨¡å¼
                    if grok_resp.get("imageAttachmentInfo"):
                        is_image = True

                    # è·å–token
                    token = grok_resp.get("token", "")

                    # æå–å›¾ç‰‡æ•°æ®
                    if is_image:
                        if model_resp := grok_resp.get("modelResponse"):
                            # è·å–å›¾ç‰‡è¿”å›æ¨¡å¼
                            image_mode = setting.global_config.get("image_mode", "url")

                            # åˆå§‹åŒ–å†…å®¹å˜é‡
                            content = ""

                            # ç”Ÿæˆå›¾ç‰‡é“¾æ¥å¹¶ç¼“å­˜
                            for img in model_resp.get("generatedImageUrls", []):
                                try:
                                    if image_mode == "base64":
                                        # base64 æ¨¡å¼ï¼šä¸‹è½½å¹¶è½¬æ¢ä¸º base64
                                        base64_str = await image_cache_service.download_base64(f"/{img}", auth_token)
                                        if base64_str:
                                            # åˆ†å—å‘é€ base64 æ•°æ®ï¼Œæ¯ 8KB ä¸€ä¸ª chunk
                                            markdown_prefix = "![Generated Image](data:"
                                            markdown_suffix = ")\n"

                                            # æå– data URL çš„ mime å’Œ base64 éƒ¨åˆ†
                                            if base64_str.startswith("data:"):
                                                parts = base64_str.split(",", 1)
                                                if len(parts) == 2:
                                                    mime_part = parts[0] + ","
                                                    b64_data = parts[1]

                                                    # å‘é€å‰ç¼€
                                                    yield make_chunk(markdown_prefix + mime_part)
                                                    timeout_manager.mark_chunk_received()
                                                    chunk_index += 1

                                                    # åˆ†å—å‘é€ base64 æ•°æ®
                                                    chunk_size = 8192
                                                    for i in range(0, len(b64_data), chunk_size):
                                                        chunk_data = b64_data[i:i + chunk_size]
                                                        yield make_chunk(chunk_data)
                                                        timeout_manager.mark_chunk_received()
                                                        chunk_index += 1

                                                    # å‘é€åç¼€
                                                    yield make_chunk(markdown_suffix)
                                                    timeout_manager.mark_chunk_received()
                                                    chunk_index += 1
                                                else:
                                                    yield make_chunk(f"![Generated Image]({base64_str})\n")
                                                    timeout_manager.mark_chunk_received()
                                                    chunk_index += 1
                                            else:
                                                yield make_chunk(f"![Generated Image]({base64_str})\n")
                                                timeout_manager.mark_chunk_received()
                                                chunk_index += 1
                                        else:
                                            yield make_chunk(f"![Generated Image](https://assets.grok.com/{img})\n")
                                            timeout_manager.mark_chunk_received()
                                            chunk_index += 1
                                    else:
                                        # url æ¨¡å¼ï¼šç¼“å­˜å¹¶è¿”å›é“¾æ¥
                                        await image_cache_service.download_image(f"/{img}", auth_token)
                                        # æœ¬åœ°å›¾ç‰‡è·¯å¾„
                                        img_path = img.replace('/', '-')
                                        base_url = setting.global_config.get("base_url", "")
                                        img_url = f"{base_url}/images/{img_path}" if base_url else f"/images/{img_path}"
                                        content += f"![Generated Image]({img_url})\n"
                                except Exception as e:
                                    logger.warning(f"[Processor] å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")
                                    content += f"![Generated Image](https://assets.grok.com/{img})\n"

                            # å‘é€å†…å®¹
                            yield make_chunk(content.strip(), "stop")
                            timeout_manager.mark_chunk_received()
                            return
                        elif token:
                            yield make_chunk(token)
                            timeout_manager.mark_chunk_received()
                            chunk_index += 1

                    # æå–å¯¹è¯æ•°æ®
                    else:
                        # è¿‡æ»¤ list æ ¼å¼çš„ token
                        if isinstance(token, list):
                            continue

                        # è¿‡æ»¤ç‰¹å®šæ ‡ç­¾
                        if any(tag in token for tag in filtered_tags if token):
                            continue

                        # è·å–å½“å‰çŠ¶æ€
                        current_is_thinking = grok_resp.get("isThinking", False)
                        message_tag = grok_resp.get("messageTag")

                        # è·³è¿‡åç»­çš„ <think> æ ‡ç­¾
                        if thinking_finished and current_is_thinking:
                            continue

                        # æ£€æŸ¥ toolUsageCardId - ALWAYS stream tool usage to reduce TTFT
                        if tool_usage_id := grok_resp.get("toolUsageCardId"):
                            # Stream tool usage notification IMMEDIATELY to keep connection alive
                            if not is_thinking:
                                # Start thinking block for tool usage
                                tool_notification = f"<think>\n[Tool: {tool_usage_id}]\n"
                                yield make_chunk(tool_notification)
                                timeout_manager.mark_chunk_received()
                                chunk_index += 1
                                is_thinking = True
                            
                            if web_search := grok_resp.get("webSearchResults"):
                                # Stream web search results IMMEDIATELY
                                search_content = ""
                                for result in web_search.get("results", []):
                                    title = result.get("title", "")
                                    url = result.get("url", "")
                                    preview = result.get("preview", "")
                                    preview_clean = preview.replace("\n", "") if isinstance(preview, str) else ""
                                    search_content += f'\n- [{title}]({url} "{preview_clean}")'
                                search_content += "\n"
                                
                                # Stream search results
                                yield make_chunk(search_content)
                                timeout_manager.mark_chunk_received()
                                chunk_index += 1
                                continue
                            else:
                                # Tool usage started but no results yet - still stream notification
                                continue

                        if token:
                            content = token

                            # header åœ¨ token åæ¢è¡Œ
                            if message_tag == "header":
                                content = f"\n\n{token}\n\n"

                            # is_thinking çŠ¶æ€åˆ‡æ¢
                            if not is_thinking and current_is_thinking:
                                content = f"<think>\n{content}"
                            elif is_thinking and not current_is_thinking:
                                content = f"\n</think>\n{content}"
                                thinking_finished = True

                            yield make_chunk(content)
                            timeout_manager.mark_chunk_received()
                            chunk_index += 1
                            is_thinking = current_is_thinking

                except (json.JSONDecodeError, UnicodeDecodeError) as e:
                    logger.warning(f"[Processor] è§£æchunkå¤±è´¥: {e}")
                    continue
                except Exception as e:
                    logger.warning(f"[Processor] å¤„ç†chunkå‡ºé”™: {e}")
                    continue

            # å‘é€ç»“æŸå—
            yield make_chunk("", "stop")

            # å‘é€æµç»“æŸæ ‡è®°
            yield "data: [DONE]\n\n"
            
            # è®°å½•æµå¼å“åº”ç»Ÿè®¡
            logger.info(f"[Processor] æµå¼å“åº”å®Œæˆï¼Œæ€»è€—æ—¶: {timeout_manager.get_total_duration():.2f}ç§’")

        except Exception as e:
            logger.error(f"[Processor] æµå¼å¤„ç†ä¸¥é‡é”™è¯¯: {e}")
            yield make_chunk(f"å¤„ç†é”™è¯¯: {e}", "error")
            # å‘é€æµç»“æŸæ ‡è®°
            yield "data: [DONE]\n\n"
        finally:
            # ç¡®ä¿å“åº”å¯¹è±¡è¢«å…³é—­
            if not response_closed and hasattr(response, 'close'):
                try:
                    response.close()
                    logger.debug("[Processor] æµå¼å“åº”å¯¹è±¡å·²å…³é—­")
                except Exception as e:
                    logger.warning(f"[Processor] å…³é—­æµå¼å“åº”å¯¹è±¡æ—¶å‡ºé”™: {e}")